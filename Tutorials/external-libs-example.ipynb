{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append path to use tsad without installing\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tsad.base.task import Task, TaskResult\n",
    "from tsad.base.pipeline import Pipeline\n",
    "from tsad.tasks.eda import HighLevelDatasetAnalysisTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load external dataset - SKAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsad.base.datasets import load_skab_teaser\n",
    "\n",
    "dataset = load_skab_teaser()\n",
    "frame = dataset.frame[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn usage example\n",
    "\n",
    "External method, algorithms and classes need to wrap with `Task` to use in TSAD pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create preprocessing task with external scikit-learn StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnPreprocessingTaskResult(TaskResult):\n",
    "\n",
    "    scaler: None\n",
    "      \n",
    "    def show(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "class SklearnPreprocessingTask(Task):\n",
    "\n",
    "    def fit_predict(self, df: pd.DataFrame) -> tuple[pd.DataFrame, TaskResult]:\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df)\n",
    "\n",
    "        result = SklearnPreprocessingTaskResult()\n",
    "        result.scaler = scaler\n",
    "\n",
    "        return df, result\n",
    "\n",
    "    def predict(self, df: pd.DataFrame, result: SklearnPreprocessingTaskResult) -> tuple[pd.DataFrame, TaskResult]:\n",
    "        return pd.DataFrame(result.scaler.transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_task = SklearnPreprocessingTask()\n",
    "preprocessing_df, preprocessing_result = preprocessing_task.fit_predict(frame)\n",
    "\n",
    "preprocessed_df = preprocessing_task.predict(frame, preprocessing_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create anomaly detection task with external scikit-learn IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnAnomalyTaskResult(TaskResult):\n",
    "\n",
    "    isolation_forest: None\n",
    "      \n",
    "    def show(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "class SklearnAnomalyTask(Task):\n",
    "\n",
    "    def fit_predict(self, df: pd.DataFrame, preprocessing: SklearnPreprocessingTaskResult) -> tuple[pd.DataFrame, TaskResult]:\n",
    "        from sklearn.ensemble import IsolationForest\n",
    "\n",
    "        result = SklearnAnomalyTaskResult()\n",
    "        result.isolation_forest = IsolationForest(max_samples=100, random_state=0)\n",
    "        result.isolation_forest.fit(preprocessing.scaler.transform(df))\n",
    "\n",
    "        return df, result\n",
    "\n",
    "    def predict(self, df: pd.DataFrame, anomaly: SklearnAnomalyTaskResult, preprocessing: SklearnPreprocessingTaskResult) -> tuple[pd.DataFrame, TaskResult]:\n",
    "        return pd.DataFrame(anomaly.isolation_forest.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6405 entries, 0 to 6404\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       6405 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 50.2 KB\n"
     ]
    }
   ],
   "source": [
    "anomaly_task = SklearnAnomalyTask()\n",
    "anomaly_df, anomaly_result = anomaly_task.fit_predict(frame, preprocessing_result)\n",
    "\n",
    "anomaly_task.predict(preprocessed_df, anomaly_result, preprocessing_result).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create anomaly detection pipeline with external scikit-learn lib usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6405 entries, 0 to 6404\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       6405 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 50.2 KB\n"
     ]
    }
   ],
   "source": [
    "anomaly_pipeline = Pipeline([\n",
    "    HighLevelDatasetAnalysisTask(),\n",
    "    SklearnPreprocessingTask(),\n",
    "    SklearnAnomalyTask()\n",
    "])\n",
    "anomaly_pipeline.fit_predict(frame)\n",
    "anomaly_df = anomaly_pipeline.predict(frame)\n",
    "\n",
    "anomaly_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create forecasting task with external scikit-learn LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnForecastingTaskResult(TaskResult):\n",
    "\n",
    "    linear_regression: None\n",
    "      \n",
    "    def show(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "class SklearnForecastingTask(Task):\n",
    "\n",
    "    def fit_predict(self, df: pd.DataFrame) -> tuple[pd.DataFrame, TaskResult]:\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        result = SklearnForecastingTaskResult()\n",
    "        result.linear_regression = LinearRegression()\n",
    "        train_list = train_test_split(df)\n",
    "        result.linear_regression.fit(train_list[0].tail(len(train_list[1])), train_list[1])\n",
    "\n",
    "        return df, result\n",
    "\n",
    "    def predict(self, df: pd.DataFrame, anomaly: SklearnForecastingTaskResult) -> tuple[pd.DataFrame, TaskResult]:\n",
    "        return pd.DataFrame(anomaly.linear_regression.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6405 entries, 0 to 6404\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6405 non-null   float64\n",
      " 1   1       6405 non-null   float64\n",
      " 2   2       6405 non-null   float64\n",
      " 3   3       6405 non-null   float64\n",
      " 4   4       6405 non-null   float64\n",
      " 5   5       6405 non-null   float64\n",
      " 6   6       6405 non-null   float64\n",
      " 7   7       6405 non-null   float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 400.4 KB\n"
     ]
    }
   ],
   "source": [
    "forecasting_task = SklearnForecastingTask()\n",
    "forecasting_df, forecasting_result = forecasting_task.fit_predict(frame)\n",
    "\n",
    "forecasting_task.predict(frame, forecasting_result).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create forecasting pipeline with external scikit-learn lib usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6405 entries, 0 to 6404\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6405 non-null   float64\n",
      " 1   1       6405 non-null   float64\n",
      " 2   2       6405 non-null   float64\n",
      " 3   3       6405 non-null   float64\n",
      " 4   4       6405 non-null   float64\n",
      " 5   5       6405 non-null   float64\n",
      " 6   6       6405 non-null   float64\n",
      " 7   7       6405 non-null   float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 400.4 KB\n"
     ]
    }
   ],
   "source": [
    "forecasting_pipeline = Pipeline([\n",
    "    HighLevelDatasetAnalysisTask(),\n",
    "    SklearnForecastingTask()\n",
    "])\n",
    "forecasting_pipeline.fit_predict(frame)\n",
    "forecasting_df = forecasting_pipeline.predict(frame)\n",
    "\n",
    "forecasting_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
