{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526de22f",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb118206-a660-413a-9185-cbd9da3be522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "\n",
    "\n",
    "from tsad.base.pipeline import Pipeline\n",
    "from tsad.base.datasets import load_skab\n",
    "from tsad.base.wrappers import SklearnWrapper\n",
    "\n",
    "\n",
    "from tsad.tasks.eda import HighLevelDatasetAnalysisTask, TimeDiscretizationTask\n",
    "from tsad.tasks.eda import FindNaNTask, EquipmentDowntimeTask\n",
    "from tsad.tasks.preprocess import ScalingTask, ValueRangeProcessingTask, ResampleProcessingTask \n",
    "from tsad.tasks.preprocess import FeatureProcessingTask, SplitByNaNTask, PrepareSeqSamplesTask\n",
    "from tsad.tasks.deep_learning_anomaly_detection import ResidualAnomalyDetectionTask\n",
    "from tsad.tasks.deep_learning_forecasting import DeepLeaningTimeSeriesForecastingTask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01525f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c72322f1",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8495097d-dd90-45d7-b4b6-fdd8c2747596",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_skab()\n",
    "columns = dataset.feature_names\n",
    "targets = dataset.target_names\n",
    "df = dataset.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f9e381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['air/0', 'air/1', 'fluid/0', 'fluid/1', 'fluid/2', 'fluid/3', 'fluid/4',\n",
       "       'fluid/5', 'rotor/0', 'rotor/1', 'rotor/2', 'rotor/3', 'rotor/4',\n",
       "       'temperature/0', 'valve1/0', 'valve1/1', 'valve1/10', 'valve1/11',\n",
       "       'valve1/12', 'valve1/13', 'valve1/14', 'valve1/15', 'valve1/2',\n",
       "       'valve1/3', 'valve1/4', 'valve1/5', 'valve1/6', 'valve1/7', 'valve1/8',\n",
       "       'valve1/9', 'valve2/0', 'valve2/1', 'valve2/2', 'valve2/3'],\n",
       "      dtype='object', name='experiment')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.levels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42a1b1",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752af2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = ['valve1/0', 'valve2/0', 'fluid/0']\n",
    "train_raw = df.drop(test_datasets,level=0).droplevel(level=0)\n",
    "test_raw = df.loc[test_datasets].droplevel(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ffa6b",
   "metadata": {},
   "source": [
    "# Making custom task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b869c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "StandardScalerTask = SklearnWrapper(StandardScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14257b1",
   "metadata": {},
   "source": [
    "# Making pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16f7cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StandardScaler'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07570ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['s'] =12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e73455b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2149179233.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    nonlocal 'xxx' =2\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def ss():\n",
    "    nonlocal 'xxx' =2\n",
    "    print(xxx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c42fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my():\n",
    "    mys = 2 \n",
    "    locals()['newsong'] = 4\n",
    "    print(locals())\n",
    "    print(newsong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e8b4aa4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mys': 2, 'newsong': 4}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'newsong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m, in \u001b[0;36mmy\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mlocals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewsong\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnewsong\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'newsong' is not defined"
     ]
    }
   ],
   "source": [
    "my()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8723d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd4c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb8f11e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "1s\n",
      "{'sample_weight': 'sdsd'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'sdsd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:13\u001b[0m\n",
      "File \u001b[1;32m~\\YandexDisk\\tsad\\Tutorials\\..\\tsad\\base\\pipeline.py:123\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, df, **params)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: pd\u001b[38;5;241m.\u001b[39mDataFrame, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m PipelineMode\u001b[38;5;241m.\u001b[39mFIT\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32m~\\YandexDisk\\tsad\\Tutorials\\..\\tsad\\base\\pipeline.py:89\u001b[0m, in \u001b[0;36mPipeline._run\u001b[1;34m(self, df, **params)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m PipelineMode\u001b[38;5;241m.\u001b[39mFIT:\n\u001b[0;32m     88\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_method_parameters(task\u001b[38;5;241m.\u001b[39mfit, task_df)\n\u001b[1;32m---> 89\u001b[0m     task_result \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameters)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m PipelineMode\u001b[38;5;241m.\u001b[39mPREDICT:\n\u001b[0;32m     91\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_method_parameters(task\u001b[38;5;241m.\u001b[39mpredict, task_df)\n",
      "File \u001b[1;32m~\\YandexDisk\\tsad\\Tutorials\\..\\tsad\\base\\wrappers.py:24\u001b[0m, in \u001b[0;36mSklearnWrapper.<locals>.SklearnWrappedTask.fit\u001b[1;34m(self, df, sklearn_kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m,df:pd\u001b[38;5;241m.\u001b[39mDataFrame,sklearn_kwargs):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sklearn_kwargs)\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msklearnClass\u001b[38;5;241m.\u001b[39mfit(df,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msklearn_kwargs)\n\u001b[0;32m     25\u001b[0m     new_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sklearn_predict(df)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n",
      "File \u001b[1;32m~\\.conda\\envs\\tsad\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tsad\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:871\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    868\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 871\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[43m_check_sample_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;66;03m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# This is needed for the incremental computation of the var\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# See incr_mean_variance_axis and _incremental_mean_variance_axis\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# transform it to a NumPy array of shape (n_features,) required by\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# incr_mean_variance_axis and _incremental_variance_axis\u001b[39;00m\n\u001b[0;32m    880\u001b[0m dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint64 \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\.conda\\envs\\tsad\\lib\\site-packages\\sklearn\\utils\\validation.py:1766\u001b[0m, in \u001b[0;36m_check_sample_weight\u001b[1;34m(sample_weight, X, dtype, copy, only_non_negative)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1765\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1766\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1774\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample weights must be 1D array or scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tsad\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tsad\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'sdsd'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "    HighLevelDatasetAnalysisTask(),\n",
    "    TimeDiscretizationTask(freq_tobe_approach='custom',FREQ_TOBE='1s'),# freq_tobe='1s'),\n",
    "    FindNaNTask(),\n",
    "    EquipmentDowntimeTask(),\n",
    "    ResampleProcessingTask(),\n",
    "    StandardScalerTask(),\n",
    "    FeatureProcessingTask(),\n",
    "    SplitByNaNTask(),\n",
    "    PrepareSeqSamplesTask(len_seq=10),\n",
    "    DeepLeaningTimeSeriesForecastingTask(),\n",
    "], show=False)\n",
    "train = pipeline.fit(train_raw,n_epochs=2,sklearn_kwargs={'sample_weight':'sdsd'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a010eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.tasks[-2].kwargs['test_size'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e0b2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущено 5 датастов, из-за того что saples слишком малов в датасете. (len_seq + points_ahead + gap -1 <= len(df))\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors, or that you (the operator writer) forgot to register a fallback function.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, AutocastCPU, Autocast, Batched, VmapMode, Functionalize].\n\nCPU: registered at aten\\src\\ATen\\RegisterCPU.cpp:21063 [kernel]\nCUDA: registered at aten\\src\\ATen\\RegisterCUDA.cpp:29726 [kernel]\nQuantizedCPU: registered at aten\\src\\ATen\\RegisterQuantizedCPU.cpp:1258 [kernel]\nBackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ..\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradCPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradCUDA: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradXLA: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradLazy: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradXPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradMLC: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradHPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradNestedTensor: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse1: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse2: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse3: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nTracer: registered at ..\\torch\\csrc\\autograd\\generated\\TraceType_3.cpp:11220 [kernel]\nAutocastCPU: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:461 [backend fallback]\nAutocast: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ..\\aten\\src\\ATen\\BatchingRegistrations.cpp:1059 [backend fallback]\nVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at ..\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:52 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_raw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\YandexDisk\\tsad\\Tutorials\\..\\tsad\\base\\pipeline.py:129\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, df, **params)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: pd\u001b[38;5;241m.\u001b[39mDataFrame, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m PipelineMode\u001b[38;5;241m.\u001b[39mPREDICT\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32m~\\YandexDisk\\tsad\\Tutorials\\..\\tsad\\base\\pipeline.py:92\u001b[0m, in \u001b[0;36mPipeline._run\u001b[1;34m(self, df, **params)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m PipelineMode\u001b[38;5;241m.\u001b[39mPREDICT:\n\u001b[0;32m     91\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_method_parameters(task\u001b[38;5;241m.\u001b[39mpredict, task_df)\n\u001b[1;32m---> 92\u001b[0m     task_result \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameters)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot supported pipeline mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\YandexDisk\\tsad\\Tutorials\\..\\tsad\\tasks\\deep_learning_forecasting.py:354\u001b[0m, in \u001b[0;36mDeepLeaningTimeSeriesForecastingTask.predict\u001b[1;34m(self, dfs, result, points_ahead, n_epochs, len_seq, batch_size, encod_decode_model, random_state, shuffle, show_progress, show_figures, best_model_file)\u001b[0m\n\u001b[0;32m    351\u001b[0m all_data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoader(X_test, y_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m##### !!!!!!!!!!!!!!!  c X_test, y_test точно ошибка\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_data_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforecast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints_ahead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints_ahead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, result\n",
      "File \u001b[1;32m~\\YandexDisk\\tsad\\Tutorials\\..\\tsad\\utils\\MLmodels\\DeepLearningRegressors.py:163\u001b[0m, in \u001b[0;36mSimpleLSTM.run_epoch\u001b[1;34m(self, iterator, optimizer, criterion, points_ahead, phase, device, encod_decode_model)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(iterator)\u001b[38;5;66;03m#, n_true_predicted / n_predicted\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_y_preds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors, or that you (the operator writer) forgot to register a fallback function.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, AutocastCPU, Autocast, Batched, VmapMode, Functionalize].\n\nCPU: registered at aten\\src\\ATen\\RegisterCPU.cpp:21063 [kernel]\nCUDA: registered at aten\\src\\ATen\\RegisterCUDA.cpp:29726 [kernel]\nQuantizedCPU: registered at aten\\src\\ATen\\RegisterQuantizedCPU.cpp:1258 [kernel]\nBackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ..\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradCPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradCUDA: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradXLA: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradLazy: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradXPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradMLC: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradHPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradNestedTensor: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse1: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse2: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse3: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:11380 [autograd kernel]\nTracer: registered at ..\\torch\\csrc\\autograd\\generated\\TraceType_3.cpp:11220 [kernel]\nAutocastCPU: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:461 [backend fallback]\nAutocast: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ..\\aten\\src\\ATen\\BatchingRegistrations.cpp:1059 [backend fallback]\nVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at ..\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:52 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "pipeline.predict(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a783d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss(b=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa538a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11454f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf242cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(pipeline.tasks[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = PrepareSeqSamplesTask(len_seq=10)\n",
    "(X_train, _, y_train, _) , _ = task.fit(train)\n",
    "\n",
    "task = PrepareSeqSamplesTask(len_seq=10)\n",
    "(_, X_test, _, y_test), _ = task.fit(test)\n",
    "\n",
    "dfs = [X_train,X_test,y_train,y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9613a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ResidualAnomalyDetectionTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3ebed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "task.fit(dfs,result_base_eda=fit_pipeline.results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25277145",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = DeepLeaningTimeSeriesForecastingTask()\n",
    "task.fit(dfs,result_base_eda=fit_pipeline.results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b77c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5fb9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdee4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsad",
   "language": "python",
   "name": "tsad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
